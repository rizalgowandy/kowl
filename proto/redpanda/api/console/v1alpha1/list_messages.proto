syntax = "proto3";

package redpanda.api.console.v1alpha1;

import "buf/validate/validate.proto";
import "redpanda/api/console/v1alpha1/common.proto";

// ListMessagesRequest is the request for ListMessages call.
message ListMessagesRequest {
  string topic = 1 [
    (buf.validate.field).string.min_len = 1,
    (buf.validate.field).string.max_len = 249,
    (buf.validate.field).string.pattern = "^[a-zA-Z0-9._\\-]*$"
  ]; // Topic name.

  sint64 start_offset = 2 [(buf.validate.field).sint64 = {
    in: [
      -1,
      -2,
      -3,
      -4
    ]
  }]; // Start offset. -1 for recent (newest - results), -2 for oldest offset, -3 for newest, -4 for timestamp.

  int64 start_timestamp = 3; // Start offset by unix timestamp in ms (only considered if start offset is set to -4).
  int32 partition_id = 4 [(buf.validate.field).int32 = {gte: -1}]; // -1 for all partition ids
  int32 max_results = 5; // Maximum number of results
  string filter_interpreter_code = 6; // Base64 encoded code
  bytes enterprise = 7; // Enterprise may only be set in the Enterprise mode. The JSON deserialization is deferred.

  bool troubleshoot = 8; // Optionally include troubleshooting data in the response.
  bool include_original_raw_payload = 9; // Optionally include original raw payload.

  optional PayloadEncoding key_deserializer = 10; // Optionally specify key payload deserialization strategy to use.
  optional PayloadEncoding value_deserializer = 11; // Optionally specify value payload deserialization strategy to use.

  bool ignore_max_size_limit = 12; // Optionally ignore configured maximum payload size limit.
  // Used to force returning deserialized payloads.
}

// ListMessagesResponse is the response for ListMessages call.
message ListMessagesResponse {
  // Data control message.
  message DataMessage {
    int32 partition_id = 1;
    int64 offset = 2;
    int64 timestamp = 3;
    CompressionType compression = 4;
    bool is_transactional = 5;

    repeated KafkaRecordHeader headers = 6; // Kafka record headers.
    KafkaRecordPayload key = 7; // Kafka key of the payload record.
    KafkaRecordPayload value = 8; // Kafka value of the payload record.
  }

  // Phase control message.
  message PhaseMessage {
    string phase = 1; // The current phase.
  }

  // Progress control message.
  message ProgressMessage {
    int64 messages_consumed = 1; // Currently consumed messages.
    int64 bytes_consumed = 2; // Currently consumed bytes.
  }

  // Stream completed control message.
  message StreamCompletedMessage {
    int64 elapsed_ms = 1; // Total elapsed time in milliseconds.
    bool is_cancelled = 2; // Whether the call was cancelled.
    int64 messages_consumed = 3; // Total consumed messages.
    int64 bytes_consumed = 4; // Total consumed bytes.
  }

  // Error control message.
  message ErrorMessage {
    string message = 1; // The error message.
  }

  // The control message as we consume messages.
  oneof control_message {
    DataMessage data = 1;
    PhaseMessage phase = 2;
    ProgressMessage progress = 3;
    StreamCompletedMessage done = 4;
    ErrorMessage error = 5;
  }
}

// KafkaRecordPayload is record payload representation.
message KafkaRecordPayload {
  optional bytes original_payload = 1; // Original raw binary payload.
  optional bytes normalized_payload = 2; // Normalized user friendly representation of the payload.
  PayloadEncoding encoding = 3; // Payload encoding if we have been able to detect.
  optional int32 schema_id = 4; // Optionally, the schema ID used to deserialized the message.
  int32 payload_size = 5; // Payload size in bytes.
  bool is_payload_too_large = 6; // If payload is too large for deserialization.
  repeated TroubleshootReport troubleshoot_report = 7; // Troubleshooting data for debugging.
}
